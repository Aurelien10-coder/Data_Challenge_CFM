{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fonctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_benchmark_model():\n",
    "\n",
    "    inputs = layers.Input(shape=(100, 19))\n",
    "\n",
    "    gru_fwd = layers.GRU(64, return_sequences=False)(inputs)\n",
    "    gru_bwd = layers.GRU(64, return_sequences=False, go_backwards=True)(inputs)\n",
    "\n",
    "    concatenated = layers.concatenate([gru_fwd, gru_bwd])\n",
    "    dense_1 = layers.Dense(64, activation='selu')(concatenated)\n",
    "    dense_2 = layers.Dense(128, activation='selu')(dense_1)\n",
    "    dense_3 = layers.Dense(128, activation='selu')(dense_2)\n",
    "    dense_4 = layers.Dense(64, activation='selu')(dense_3)\n",
    "    output = layers.Dense(24, activation='softmax')(dense_4)\n",
    "\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=output)\n",
    "    \n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=3e-3),\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Création de la base de donnée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_intitial=pd.read_csv(\"/Users/aurelientarroux/Desktop/Projet_prog/Projet_2/Data/X_train_N1UvY30.csv\")  \n",
    "y_train_intitial=pd.read_csv(\"/Users/aurelientarroux/Desktop/Projet_prog/Projet_2/Data/y_train_or6m3Ta.csv\") \n",
    "X_test_initial=pd.read_csv(\"/Users/aurelientarroux/Desktop/Projet_prog/Projet_2/Data/X_test_m4HAPAP.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_base(X):\n",
    "    X['bid_ask_spread']=X['ask']-X['bid']\n",
    "    X['trade']=X['trade'].astype(int)\n",
    "\n",
    "    value_categor=['venue','action','side']\n",
    "\n",
    "    for k in value_categor:\n",
    "\n",
    "        X_encoded = pd.get_dummies(X[k], prefix=k).astype(int)\n",
    "        X = X.merge( X_encoded , left_index = True , right_index = True)\n",
    "        X.drop( columns=[k] , inplace = True )\n",
    "\n",
    "    X.drop(columns=['obs_id','order_id'],inplace=True)\n",
    "\n",
    "\n",
    "    value_no_center=['price' , 'bid' , 'ask' , 'bid_size', 'ask_size', 'bid_ask_spread' ]\n",
    "\n",
    "    for k in value_no_center:\n",
    "    \n",
    "        X[k] = X[k] / max( X[k] )\n",
    "\n",
    "    X = X.values.reshape(int(X.shape[0]/100), 100, 19)\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data_base(X_train_intitial), y_train_intitial['eqt_code_cat'].values, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_benchmark_model()\n",
    "history = model.fit(X_train, y_train, batch_size = 1000, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_prob = model.predict(X_test)\n",
    "y_pred = []\n",
    "for k in prediction_prob :\n",
    "    y_pred += [ k.argmax() ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mise en place du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train_intitial['eqt_code_cat'].values\n",
    "X_train = data_base(X_train_intitial)\n",
    "X_test = data_base(X_test_initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_benchmark_model()\n",
    "history = model.fit(X_train, y_train, batch_size = 1000, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_prob = model.predict(X_test)\n",
    "y_pred_brut= []\n",
    "for k in prediction_prob :\n",
    "    y_pred_brut += [ k.argmax() ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pd.DataFrame(y_pred_brut)\n",
    "y_pred.reset_index(inplace=True)\n",
    "y_pred.columns=y_train_intitial.columns\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred.to_csv('export_data_2.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
